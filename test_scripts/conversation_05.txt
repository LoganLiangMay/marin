Conversation 5: Mobile Gaming User Acquisition Manager
Profile:
* Role: UA Manager at mobile game studio
* Experience: 5 years in mobile gaming
* Manages: $500K monthly ad spend
* Platforms: Facebook, Google UAC, Apple Search Ads, Unity Ads, ironSource
Opening: Rep: "Hey Kevin, thanks so much for taking the time today. I'm Alex with the Marin team at Gauntlet. We're doing a round of short conversations with marketing teams and agencies to really understand how they're running campaigns right now  what's working, what's painful, and where automation could make life easier. This isn't a sales call  it's more of a discovery session so we can learn from your experience. Does that sound good?"
Kevin: "Yeah, cool. Mobile gaming UA is pretty different from other performance marketing, so hopefully what I share is useful."
Warm-Up: Rep: "Awesome. To start, could you tell me a bit about your business and what your role looks like day-to-day?"
Kevin: "We're a mid-size mobile game studio with about five games in market. I focus on user acquisition for our flagship game - getting installs profitably. Day-to-day is checking overnight performance from different geos, analyzing cohort data, testing new ad networks, working with our creative team on ad concepts, and trying to hit our LTV:CAC targets. Mobile gaming is super data-intensive."
Rep: "What does a typical week look like for you right now?"
Kevin: "Every morning starts with checking overnight performance - we advertise globally, so campaigns run 24/7. Then I'm optimizing - adjusting bids, turning off underperforming ad sets, scaling winners. Couple times a week I have creative reviews with our video team. I spend a lot of time in our BI tools looking at Day 7, Day 30 LTV by cohort. And I'm constantly testing new networks and placements - the landscape changes fast in mobile."
Rep: "What's been going really well lately?"
Kevin: "Apple Search Ads is printing money for us right now - people searching for our game genre convert really well. Google UAC has gotten better with their creative automation. We've also figured out our creative formula for playable ads - our IPM has gone up like 30%. And our Day 7 retention is trending up, which gives us more room to spend."
Rep: "And on the flip side, what's been harder than expected?"
Kevin: "ATT has been devastating. We lost probably 60-70% of our iOS targeting precision. CPIs have gone up across the board. Finding scale is really hard - we can profitably acquire maybe 2,000 installs per day, but to grow we need 10,000+ and every time we try to scale, efficiency tanks. Android is also getting more competitive - everyone's piling into Android because iOS is so hard now."
Deep Dive: Rep: "What are your biggest challenges when running ad campaigns right now?"
Kevin: "Three things keep me up. One, attribution and measurement - with ATT and probabilistic matching, I'm making decisions on incomplete data. Two, creative performance is wildly inconsistent - an ad that works great one week dies the next week. Three, the constant platform changes. Every ad network changes their algorithm, updates their targeting options, or shifts their auction dynamics. What worked last month might not work this month."
Rep: "Walk me through a recent campaign that was tough or frustrating  what happened?"
Kevin: "Last month we tried to scale into a new geo - Brazil. We translated our top-performing creative, launched campaigns across Facebook, Google, and Unity. First week looked great - CPIs were lower than our target. Then week two, retention numbers came in and they were terrible - like 40% worse than our core geos. Turned out the creative that works in US and Europe doesn't resonate in Brazil at all. By the time we realized and pivoted, we'd spent like $40K on users who are probably going to churn. That's the problem with mobile - you don't know if installs are good until days or weeks later."
Rep: "When something goes wrong, where does it usually happen?"
Kevin: "Usually it's either targeting issues or creative fatigue. Like, Facebook's Advantage+ will suddenly shift spend to a terrible placement and CPIs spike. Or an ad creative that's been working for weeks suddenly hits fatigue and performance craters. The algorithms are also black boxes - something changes, we don't know why, and we have to react. With probabilistic attribution, I'm never 100% sure what's actually working."
Rep: "How do you onboard new campaigns? What's that process like from start to finish?"
Kevin: "Depends on the network. For Facebook, I'm setting up multiple campaigns with different creative approaches, audiences, and optimization goals. Takes maybe 2-3 hours to build out a full test. Then I let it run for 3-5 days to exit the learning phase. Meanwhile, I'm setting up tracking in our MMP - making sure installs are attributing correctly. After a week, I look at cohort data and decide what to scale. Similar process for Google UAC and other networks. It's pretty manual - lots of campaign creation, tracking setup, testing."
Rep: "Do you mostly configure and let things run, or do you have to stay hands-on daily?"
Kevin: "Super hands-on. I'm in the platforms multiple times per day. Creative fatigue is real in mobile - an ad can go from performing well to terrible in 24 hours. I'm constantly monitoring IPM, CPI, and early retention signals. And I'm moving budgets around between networks based on what's working. Can't just set it and forget it in this space."
Rep: "What tools or platforms are you using today?"
Kevin: "Ad networks - Facebook, Google UAC, Apple Search Ads, Unity, ironSource, AppLovin, Vungle. We use Adjust as our MMP for attribution. Data analysis in Looker and Google Sheets. Creative testing we use a mix of internal tools and Playable Factory. And honestly, our game's own analytics dashboard to track retention and monetization. That's where the real answer is - did these users make us money?"
Rep: "What do you love about them? What's frustrating?"
Kevin: "Love: Apple Search Ads is straightforward and works. Google UAC has gotten way better at creative optimization. Adjust gives us good attribution data. Frustrating: Every network has different metrics, different attribution windows, different ways of reporting. Facebook calls it CPA, Google calls it CPI, Unity has its own terminology. Reconciling data across networks is painful. And MMPs charge a fortune for attribution - we're paying like $30K+ annually just for tracking."
Rep: "Where do you feel automation breaks down or still needs humans?"
Kevin: "Creative strategy and cohort analysis. Platforms can optimize bids, but they can't tell me if the users we're acquiring are actually valuable long-term. That requires looking at Day 7, Day 30 LTV data and making strategic decisions. Also, algorithms optimize for installs or early actions, but don't understand lifetime value. I have to manually shift budgets to campaigns driving high-LTV users, even if their Day 1 metrics look worse."
Rep: "How much time do you spend each week on manual reporting or analysis?"
Kevin: "Probably 10-12 hours per week pulling data, analyzing cohorts, building reports for our executive team. Every Monday I'm building a performance deck showing last week's installs, spend, CPIs, retention curves, and LTV projections. It's mostly manual - exporting CSVs from each network, matching to cohort data from Adjust and our game analytics, building charts in Google Sheets."
Rep: "If you could get those hours back, what would you do with that time?"
Kevin: "Test more aggressively. We should be testing way more creative concepts, more ad networks, more geo expansions. But I'm so busy managing existing campaigns and doing reporting that I don't have time to experiment. I'd also love to do deeper analysis - like, what creative themes actually drive high-LTV users? But that requires combining ad platform data with in-game behavior data, which is super manual."
Strategy + Measurement: Rep: "How are you thinking about incrementality and attribution right now?"
Kevin: "Attribution is hard in mobile. We use Adjust for install attribution, but with ATT, a huge chunk of iOS installs are 'probabilistic' or even 'unknown.' We basically have to run on faith that our spend is working. For incrementality, we occasionally run geo tests - advertise in some cities, not others, see if there's a lift. But it's not something we do systematically. Mostly we trust that if our blended LTV:CAC is above target, we're good."
Rep: "How has ATT changed your strategy?"
Kevin: "Completely reshaped it. Pre-ATT, we could do really granular retargeting and lookalike audiences on iOS. Now it's much broader targeting. We've had to get way better at creative because we can't rely on targeting precision. We've also shifted more budget to Android where we still have better targeting. And we're investing more in ASA because Apple's own ad platform obviously has better data than third parties."
Rep: "Are you experimenting with any new measurement approaches?"
Kevin: "We're using SKAN for iOS attribution now, which is... okay. Better than nothing but way less granular than IDFA was. We're also starting to use fingerprinting more for Android. And we're building out more sophisticated LTV models - trying to predict Day 90 LTV from Day 1 behavior so we can optimize faster. But honestly, a lot of it is just accepting more uncertainty than we used to have."
Rep: "What's your biggest headache when it comes to stakeholder reporting?"
Kevin: "Explaining why we can't just 'spend more' when things are working. Leadership sees we're acquiring users profitably and asks why we don't 5x the budget. But in mobile, scale and efficiency are inversely correlated - the more you spend, the worse your CPIs get. I'm constantly educating on how auction dynamics work and why hitting our targets at current scale doesn't mean we can just scale infinitely."
Vision & Desired Future: Rep: "If you could wave a magic wand and fix one thing about your workflow, what would it be?"
Kevin: "Unified performance dashboard across all networks with cohort data integrated. I want to see in real-time which campaigns are driving valuable users, not just cheap installs. Right now, that requires stitching together three different data sources manually. If I could log into one dashboard and see everything, that would change my life."
Rep: "What would an ideal system look like for you?"
Kevin: "Something that shows me campaign performance, but weighted by LTV not just CPI. Like, 'Campaign A has a $3 CPI but $8 Day 30 LTV, scale it up. Campaign B has a $2 CPI but $4 Day 30 LTV, kill it.' The platforms optimize for installs because that's what they can measure, but I care about valuable users. I need a system that bridges that gap."
Rep: "What's one thing that would make you look like a hero internally?"
Kevin: "If I could consistently scale spend while maintaining or improving efficiency. Right now, we're stuck at a local maximum - we're profitable but can't grow. If I could find a way to 2x or 3x our daily install volume without tanking our LTV:CAC ratio, I'd be a hero. That probably requires better creative testing or new network discovery."
Rep: "Where do you think the biggest opportunities for automation or AI could be?"
Kevin: "Creative testing at scale. We should be generating hundreds of ad variants, testing them across networks, and automatically scaling winners. Right now, we produce maybe 10 new creatives per month and manually deploy them. If AI could handle creative production and testing, we'd iterate way faster. Also, automated budget optimization across networks based on LTV, not just CPI. Shift budget from low-LTV sources to high-LTV sources automatically."
Wrap-Up: Rep: "That's super helpful  thank you for walking me through all that. Just to recap, I heard that unified cross-network reporting with LTV integration, creative testing at scale, and dealing with post-ATT measurement challenges are your top three pains. Did I get that right?"
Kevin: "Yeah, exactly. Mobile UA is all about making smart decisions with imperfect data, and anything that improves my data quality or decision-making is valuable."
Rep: "We're compiling insights from these conversations to shape some early prototypes. Would you be open to us showing you what we're working on when it's ready?"
Kevin: "For sure. Always looking for better tools in this space."
Post-Call Notes:
* Company: Mobile game studio, $500K monthly spend, flagship game focus
* Top 3 Pains: (1) Unified performance view across ad networks with LTV data, (2) Creative testing and production at scale, (3) Post-ATT attribution uncertainty
* Tools Used: Facebook, Google UAC, Apple Search Ads, Unity, ironSource, Adjust (MMP), Looker
* Workarounds: Manual CSV exports, stitching attribution with cohort data in spreadsheets
* Key Quotes: "Can't just set and forget in mobile", "Platforms optimize for installs, I care about valuable users", "Making decisions with imperfect data"
* Emotional Energy: Frustrated by measurement challenges, energized by creative testing opportunities
* Follow-up: Yes

